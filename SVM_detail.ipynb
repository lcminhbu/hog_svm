{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SVM phiên bản cũ"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Phiên bản này dùng linear kernel và tối ưu bằng thuật toán gradient descent.\n",
        "\n",
        "Linear kernel: w * x + b \n",
        "\n",
        "Ý tưởng của phiên bản này gồm tính toán gradient của hai tham số w, b theo từng batch, sau đó dùng gradient này để cập nhật lại w và b."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fit(self, X, Y, batch_size=100, learning_rate=0.001, epochs=1000):\n",
        "        # số thuộc tính\n",
        "        number_of_features = X.shape[1]\n",
        "\n",
        "        # số mẫu\n",
        "        number_of_samples = X.shape[0]\n",
        "\n",
        "        c = self.C\n",
        "\n",
        "        # mảng index để truy xuất dữ liệu trong từng batch\n",
        "        ids = np.arange(number_of_samples)\n",
        "\n",
        "        # hoán vị các mẫu\n",
        "        np.random.shuffle(ids)\n",
        "\n",
        "        # khởi tạo các giá trị w,b và losses\n",
        "        w = np.zeros((1, number_of_features))\n",
        "        b = 0\n",
        "        losses = []\n",
        "\n",
        "        # Thuật toán gradient descent\n",
        "        for i in range(epochs):\n",
        "            # tính toán hàm mất mát\n",
        "            l = self.hingeloss(w, b, X, Y)\n",
        "            losses.append(l)\n",
        "            \n",
        "            #tính toán gradient của w và b trong từng batch\n",
        "            for batch_initial in range(0, number_of_samples, batch_size):\n",
        "                gradw = 0\n",
        "                gradb = 0\n",
        "\n",
        "                # Với mỗi phần tử trong batch tính:\n",
        "                # ti = y * ((w @ x) + b)\n",
        "                # nếu ti <= 1 thì gradient được cập nhật như sau:\n",
        "                # gradw = gradw + c * y * x\n",
        "                # gradb = gradb + c * y\n",
        "                # sau khi đã tính toán xong gradient trong batch thì w và b được cập nhật\n",
        "                # w = w - learning_rate * w + learning_rate * gradw\n",
        "                # b = b + learning_rate * gradb\n",
        "                for j in range(batch_initial, batch_initial + batch_size):\n",
        "                    if j < number_of_samples:\n",
        "                        x = ids[j]\n",
        "                        ti = Y[x] * (np.dot(w, X[x].T) + b)\n",
        "\n",
        "                        if ti > 1:\n",
        "                            gradw += 0\n",
        "                            gradb += 0\n",
        "                        else:\n",
        "                            # tính toán gradient\n",
        "                            gradw += c * Y[x] * X[x]\n",
        "                            gradb += c * Y[x]\n",
        "\n",
        "                # Cập nhật w và b\n",
        "                w = w - learning_rate * w + learning_rate * gradw\n",
        "                b = b + learning_rate * gradb\n",
        "        \n",
        "        self.w = w\n",
        "        self.b = b\n",
        "\n",
        "        return self.w, self.b, losses"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NUz0iBTqpRX0"
      },
      "source": [
        "## SVM phiên bản tuần tự"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "va_dSy3KF_9r"
      },
      "source": [
        "### Phương pháp phân rã"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BL5Ybf9VGCta"
      },
      "source": [
        "Phương pháp này điều chỉnh tập con của alpha trong mỗi vòng lặp, do đó chỉ vài cột Q là cần thiết (Q là một ma trận dày - dense và có thể rất lớn để lưu trữ). Tập con của những biến này thường được gọi là tập làm việc (working set) B, dẫn đến một vấn đề tối ưu phụ nhỏ hơn.\n",
        "\n",
        "Bởi vì chỉ có một vài thành phần được cập nhật trong mỗi vòng lặp, với những bài toán khó, phương pháp phân rã này có sự hội tụ chậm. Những phương pháp tốt hơn cho việc lựa chọn tập làm việc có thể giảm số vòng lặp xuống."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3WfXhSe6JE3s"
      },
      "source": [
        "### Hàm tính Q"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7ScCk3XJNN2"
      },
      "source": [
        "Q là ma trận đối xứng với từng phần tử được tính theo công thức $Q_{ij} = y_iy_jK(x_i, x_j)$ với $K(x_i, x_j)$ là hàm kernel."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```python\n",
        "def get_Q(self, X, i, j):\n",
        "  if self.Q[i, j] == None:\n",
        "    self.Q[i][j] = self.y[i] * self.y[j] * self.get_K(X, i, j)\n",
        "    self.Q[j][i] = self.Q[i][j]\n",
        "  return self.Q[i][j] \n",
        "```"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "B31rRTOaxnwd"
      },
      "source": [
        "### Hàm lựa chọn bộ làm việc (working set selection - WSS)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vv_Us9C7OxjB"
      },
      "source": [
        "**WSS 3**\n",
        "\n",
        "**(Working set selection using second order information: any symmetric $K$)**\n",
        "\n",
        "1. Định nghĩa $a_{ts}$ và $b_{ts}$ như sau:\n",
        "\n",
        "$a_{ts} \\equiv K_{tt} + K_{ss} - 2K_{ts} > 0$ và $b_{ts} \\equiv -y_t \\nabla f(\\alpha^k)_t + y_s \\nabla f(\\alpha^k)_s > 0$\n",
        "\n",
        "và\n",
        "\n",
        "$\\bar a \\equiv \\Biggl\\{ {a_{ts} \\; nếu \\; a_{ts} > 0, \\\\ \\tau \\; khác.}$\n",
        "\n",
        "Chọn\n",
        "\n",
        "$i \\in arg max_t \\{-y_t \\nabla f(\\alpha^k)_t | t \\in I_{up}(\\alpha^k)\\}$\n",
        "\n",
        "$j \\in argmin_t \\{ -\\frac{b^2_{it}}{\\bar a_{it}} | t \\in I_{low}(\\alpha^k), -y_t \\nabla f(\\alpha^k)_t < -y_i \\nabla f(\\alpha^k)_i \\}  $\n",
        "\n",
        "2. Trả về $B = \\{i, j\\}$"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CKFlfYi3yUWx"
      },
      "source": [
        "Đây là một phương pháp trong việc phân rã để huấn luyện thuật toán SVM. Thuật toán này dùng đạo hàm bậc hai cho bất kỳ ma trận K đối xứng nào. Hàm này giải quyết được vấn đề chứng minh sự hội tụ của phương pháp phân rã. Đồng thời thuật toán này cũng giảm số vòng lặp."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```python\n",
        "def select_B(self, X):\n",
        "  i = -1\n",
        "  G_max = -np.inf\n",
        "  G_min = np.inf\n",
        "  for t in range(self.l):\n",
        "    if (self.y[t] == 1 and self.alphas[t] <self.C) or \\\n",
        "    (self.y[t] == -1 and self.alphas[t] > 0):\n",
        "      if -self.y[t] * self.G[t] >= G_max:\n",
        "        i = t\n",
        "        G_max = -self.y[t] * self.G[t]\n",
        "        \n",
        "  j = -1\n",
        "  obj_min = np.inf\n",
        "  for t in range(self.l):\n",
        "    if (self.y[t]==1 and self.alphas[t]>0) or \\\n",
        "        (self.y[t] == -1 and self.alphas[t] < self.C):\n",
        "      b = G_max + self.y[t] * self.G[t]\n",
        "      if -self.y[t]*self.G[t] <= G_min:\n",
        "        G_min = -self.y[t] * self.G[t]\n",
        "      if b>0:\n",
        "        a = self.get_Q(X, i, i) + self.get_Q(X, t, t) - 2.0*self.y[i]*self.y[t]*self.get_Q(X, i, t)\n",
        "        if a<=0:\n",
        "          a = self.tau\n",
        "        if -(b*b)/a <= obj_min:\n",
        "          j = t\n",
        "          obj_min = -(b*b)/a\n",
        "  if G_max - G_min < self.eps:\n",
        "    return -1, -1\n",
        "  return i, j\n",
        "```"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hàm này còn bao gồm công dụng kiểm tra điều kiện dừng của thuật toán `G_max - G_min < eps`"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Cập nhật Gradient"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "$\\nabla f(\\alpha^{k+1}) = \\nabla f(\\alpha^k) + Q_{:,B}(\\alpha^{k+1}-\\alpha^k)$"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```python\n",
        "for t in range(self.l):\n",
        "                self.G[t] += self.get_Q(X, i, t) * delta_ai + self.get_Q(X, j, t) *delta_aj\n",
        "```"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tìm threshold b:\n",
        "\n",
        "Ta có công thức: $-b=\\frac{\\sum_{i:0<\\alpha_i<C>}y_i\\nabla_i f (\\alpha))}{|\\{i|0<\\alpha_i<C>\\}|}$\n",
        "\n",
        "Nếu không có $\\alpha$ nào thỏa $0<\\alpha_i<C$ thì: điều kiện KKT chuyển thành:\n",
        "\n",
        "$-M(\\alpha) = max\\{y_i\\nabla_i f(\\alpha) | \\alpha_i=0,y_i=-1 \\ or\\  \\alpha_i=C,y_i=1\\}\n",
        "<=-b<=-m(\\alpha) = min\\{y_i\\nabla_i f(\\alpha) | \\alpha_i=0,y_i=1 \\ or\\  \\alpha_i=C,y_i=-1\\}$\n",
        "\n",
        "Ta sẽ chọn -b ở khoảng giữa"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```python\n",
        "    def get_b(self):\n",
        "        sum = 0.0\n",
        "        count = 0\n",
        "        for i in range(self.l):\n",
        "            if 0 < self.alphas[i] < self.C:\n",
        "                count += 1\n",
        "                sum += self.y[i] * self.G[i]\n",
        "        if count > 0:\n",
        "            self.b = sum/count\n",
        "            return\n",
        "        max = -np.inf\n",
        "        min = np.inf\n",
        "        for i in range(self.l):\n",
        "            if (self.alphas[i] == 0 and self.y[i] == -1) or \\\n",
        "                (self.alphas[i] == self.C and self.y[i] == 1):\n",
        "                    if max < self.y[i] * self.G[i]:\n",
        "                        max = self.y[i] * self.G[i]\n",
        "            if (self.alphas[i] == 0 and self.y[i] == 1) or \\\n",
        "                (self.alphas[i] == self.C and self.y[i] == -1):\n",
        "                    if min > self.y[i] *self.G[i]:\n",
        "                        min = self.y[i] * self.G[i]\n",
        "        self.b = (min+max) / 2\n",
        "```"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eNRUZjWV_yhP"
      },
      "source": [
        "### Code hoàn chỉnh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orfOvrbWo1iw"
      },
      "outputs": [],
      "source": [
        "class SVM_Se:\n",
        "    # Khởi tạo các tham số\n",
        "    def __init__(self, gamma = -1, kernel = 'rbf', C = 1.0, eps = 1e-3):\n",
        "        self.C = C\n",
        "        self.eps = eps # điều kiện dừng\n",
        "        self.gamma = gamma\n",
        "        self.tau = 1e-12\n",
        "        self.kernel = kernel\n",
        "        self.gamma = gamma\n",
        "    \n",
        "    # hàm kernel\n",
        "    def Kernel(self, x1, x2):\n",
        "        # rbf kernel\n",
        "        if self.kernel == 'rbf':\n",
        "            return self.rbf(x1, x2)\n",
        "        # linear kernel\n",
        "        if self.kernel == 'linear':\n",
        "            return self.linear(x1, x2)\n",
        "\n",
        "    # hàm tính ma trận Q\n",
        "    def get_Q(self, X, i, j):\n",
        "        if self.Q[i, j] == None:\n",
        "            self.Q[i][j] = self.y[i] * self.y[j] * self.get_K(X, i, j)\n",
        "            self.Q[j][i] = self.Q[i][j]\n",
        "        return self.Q[i][j]\n",
        "    \n",
        "    # hàm tính giá trị kernel\n",
        "    def get_K(self, X, i, j):\n",
        "        if self.K[i, j] == None:\n",
        "            self.K[i][j] = self.Kernel(X[i], X[j])\n",
        "            self.K[j][i] = self.K[i][j]\n",
        "        return self.K[i][j]\n",
        "\n",
        "    # hàm tính linear kernel là tích vô hướng của hai vecto\n",
        "    def linear(self, x1, x2):\n",
        "        x1_temp = x1.astype(np.float64)\n",
        "        x2_temp = x2.astype(np.float64)\n",
        "        return x1_temp.dot(x2_temp)\n",
        "    \n",
        "    # hàm tính rbf kernel theo công thức: e^(-gamma *(x1 @ x1 + x2 @ x2 - 2 * (x1 @ x2)))\n",
        "    def rbf(self, x1, x2):\n",
        "        x1_temp = x1.astype(np.float64)\n",
        "        x2_temp = x2.astype(np.float64)\n",
        "        return np.exp(-self.gamma * (x1_temp.dot(x1_temp) + x2_temp.dot(x2_temp) - 2.0 * x1_temp.dot(x2_temp)))\n",
        "        \n",
        "    # hàm lựa chọn bộ làm việc\n",
        "    def select_B(self, X):\n",
        "        i = -1\n",
        "        G_max = -np.inf\n",
        "        G_min = np.inf\n",
        "        for t in range(self.l):\n",
        "            if (self.y[t] == 1 and self.alphas[t] <self.C) or \\\n",
        "            (self.y[t] == -1 and self.alphas[t] > 0):\n",
        "                if -self.y[t] * self.G[t] >= G_max:\n",
        "                    i = t\n",
        "                    G_max = -self.y[t] * self.G[t]\n",
        "        j = -1\n",
        "        obj_min = np.inf\n",
        "        for t in range(self.l):\n",
        "            if (self.y[t]==1 and self.alphas[t]>0) or \\\n",
        "                (self.y[t] == -1 and self.alphas[t] < self.C):\n",
        "                    b = G_max + self.y[t] * self.G[t]\n",
        "                    if -self.y[t]*self.G[t] <= G_min:\n",
        "                        G_min = -self.y[t] * self.G[t]\n",
        "                    if b>0:\n",
        "                        a = self.get_Q(X, i, i) + self.get_Q(X, t, t) - 2.0*self.y[i]*self.y[t]*self.get_Q(X, i, t)\n",
        "                        if a<=0:\n",
        "                            a = self.tau\n",
        "                        if -(b*b)/a <= obj_min:\n",
        "                            j = t\n",
        "                            obj_min = -(b*b)/a\n",
        "        if G_max - G_min < self.eps:\n",
        "            return -1, -1\n",
        "        return i, j\n",
        "\n",
        "    # hàm dự đoán\n",
        "    def predict(self, X):\n",
        "        pred = []\n",
        "        for x in X:\n",
        "            sum = 0.0\n",
        "            for i in range(self.l):\n",
        "                sum += self.y[i] * self.alphas[i] * self.Kernel(self.X[i], x)\n",
        "            sum -= self.b\n",
        "            pred.append(np.sign(sum))\n",
        "        return pred\n",
        "\n",
        "\n",
        "    def get_b(self):\n",
        "        sum = 0.0\n",
        "        count = 0\n",
        "        for i in range(self.l):\n",
        "            if 0 < self.alphas[i] < self.C:\n",
        "                count += 1\n",
        "                sum += self.y[i] * self.G[i]\n",
        "        if count > 0:\n",
        "            self.b = sum/count\n",
        "            return\n",
        "        max = -np.inf\n",
        "        min = np.inf\n",
        "        for i in range(self.l):\n",
        "            if (self.alphas[i] == 0 and self.y[i] == -1) or \\\n",
        "                (self.alphas[i] == self.C and self.y[i] == 1):\n",
        "                    if max < self.y[i] * self.G[i]:\n",
        "                        max = self.y[i] * self.G[i]\n",
        "            if (self.alphas[i] == 0 and self.y[i] == 1) or \\\n",
        "                (self.alphas[i] == self.C and self.y[i] == -1):\n",
        "                    if min > self.y[i] *self.G[i]:\n",
        "                        min = self.y[i] * self.G[i]\n",
        "        self.b = (min+max) / 2\n",
        "\n",
        "    # hàm huấn luyện mô hình\n",
        "    def fit(self, X, y):\n",
        "        global t1\n",
        "        global t2\n",
        "        global t3\n",
        "        self.y = y\n",
        "        self.X = X\n",
        "        self.l = len(y)\n",
        "        if self.gamma == -1:\n",
        "            self.gamma = 1/(X.shape[1]*X.var())\n",
        "        self.active_size= self.l\n",
        "\n",
        "        # khởi tạo mảng alpha\n",
        "        self.alphas = np.zeros(self.l)\n",
        "        self.n_iter = 0\n",
        "\n",
        "        self.K = np.array([[None for _ in range(self.l)] for _ in range(self.l)])\n",
        "        self.Q = np.array([[None for _ in range(self.l)] for _ in range(self.l)])\n",
        "        \n",
        "        # khởi tạo mảng gradient gồm các số -1\n",
        "        self.G = np.array([-1.0 for _ in range(self.l)])\n",
        "        \n",
        "        while True:\n",
        "            i, j = self.select_B(X)\n",
        "            if j == -1:\n",
        "                break\n",
        "            self.n_iter += 1\n",
        "            alphai = self.alphas[i]\n",
        "            alphaj = self.alphas[j]\n",
        "            if y[i] != y[j]:\n",
        "                quad_coef = self.get_Q(X, i, i) + self.get_Q(X, j, j) + 2*self.get_Q(X, i, j)\n",
        "                if quad_coef <= 0:\n",
        "                    quad_coef = self.tau\n",
        "                delta = (-self.G[i] - self.G[j])/quad_coef\n",
        "                diff = alphai - alphaj\n",
        "                self.alphas[i] += delta\n",
        "                self.alphas[j] += delta\n",
        "                if diff > 0:\n",
        "                    if self.alphas[j]<0:\n",
        "                        self.alphas[j] = 0\n",
        "                        self.alphas[i] = diff\n",
        "                    if self.alphas[i]>self.C:\n",
        "                        self.alphas[i] = self.C\n",
        "                        self.alphas[j] = self.C - diff\n",
        "                else:\n",
        "                    if self.alphas[i]<0:\n",
        "                        self.alphas[i] = 0\n",
        "                        self.alphas[j] = -diff\n",
        "                    if self.alphas[j]>self.C:\n",
        "                        self.alphas[j] = self.C\n",
        "                        self.alphas[i] = self.C + diff\n",
        "            else:\n",
        "                quad_coef = self.get_Q(X, i, i) + self.get_Q(X,j,j) - 2*self.get_Q(X,i,j)\n",
        "                if quad_coef <=0:\n",
        "                    quad_coef = self.tau\n",
        "                delta = (self.G[i]-self.G[j])/quad_coef\n",
        "                sum = alphai + alphaj\n",
        "                self.alphas[i] -= delta\n",
        "                self.alphas[j] += delta\n",
        "                if sum>self.C:\n",
        "                    if self.alphas[i]>self.C:\n",
        "                        self.alphas[i] = self.C\n",
        "                        self.alphas[j] = sum-self.C\n",
        "                    if self.alphas[j]>self.C:\n",
        "                        self.alphas[j] = self.C\n",
        "                        self.alphas[i] = sum-self.C\n",
        "                else:\n",
        "                    if self.alphas[j]<0:\n",
        "                        self.alphas[j] = 0\n",
        "                        self.alphas[i] = sum\n",
        "                    if self.alphas[i]<0:\n",
        "                        self.alphas[i] = 0\n",
        "                        self.alphas[j] = sum\n",
        "            delta_ai = self.alphas[i] - alphai\n",
        "            delta_aj = self.alphas[j] - alphaj\n",
        "            for t in range(self.l):\n",
        "                self.G[t] += self.get_Q(X, i, t) * delta_ai + self.get_Q(X, j, t) *delta_aj\n",
        "        self.get_b()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ-LwprtLrw_"
      },
      "source": [
        "## SVM phiên bản song song"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Hgl8frI_LuIz"
      },
      "source": [
        "**1. Khó khăn:**\n",
        "- SMO (Sequential Minimal Optimization) bản chất là thuật toán tuần tự.\n",
        "Hầu như không phân thành các thao tác độc lập để song song.\n",
        "\n",
        "**2. Giải quyết:**\n",
        "- Phân thuật toán thành 3 giai đoạn lớn và đo tổng thời gian chạy: xác định cặp điểm cần tối ưu, tối ưu cặp điểm, cập nhật Gradient.\n",
        "\n",
        "- Thuật toán cần gọi hàm tính kernel $K(i, j)$ và tính giá trị $Q_{ij} = y_i y_j K(i, j)$ rất nhiều lần → Tính tổng thời gian mà thao tác này chiếm.\n",
        "\n",
        "**3. Song song hóa thuật toán SVM mới:**\n",
        "\n",
        "Thời gian tính $Q$ chiếm đa số thời lượng fit, dù thao tác tính $Q_{ij}$ không mất nhiều thời gian nhưng lại được gọi rất nhiều lần.\n",
        "\n",
        "→ Tìm toàn bộ $Q$ bằng song song và lưu vào 1 matrix. Khi cần chỉ cần lấy ra.\n",
        "\n",
        "Hàm Predict tốn nhiều thời gian bởi phải tính giá trị $K_{ij}$ nhiều lần (tương tự như tính $Q$ ở fit). → Giải quyết tương tự.\n",
        "\n",
        "Sau khi tính $Q$ toàn bộ, có thể cập nhật Gradient nhanh hơn bằng các thao tác với ma trận thay vì vòng for.\n",
        "\n",
        "Ngoài ra còn có thể tính dual_coef = y * alphas bằng song song thay vì lưu y và alpha để tối ưu quá trình fit.\n",
        "\n",
        "**4. Đánh giá**\n",
        "- Ưu điểm:\n",
        "\n",
        "Tối ưu hóa hiệu quả tổng thời gian fit và predict.\n",
        "\n",
        "Không có nguy cơ mất mát thông tin như cơ chế shrink của sklearn (cơ chế giúp tăng tốc khi lượng data lớn) nhưng vẫn có tốc độ cao hơn sklearn.\n",
        "\n",
        "- Nhược điểm:\n",
        "\n",
        "Tốn nhiều VRAM vì phải load toàn bộ data lên GPU để tìm $Q$.\n",
        "\n",
        "Không xác định được kích thước block tối ưu vì dữ liệu có thể ít nhiều khác nhau.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjVAjkoBOu2E"
      },
      "outputs": [],
      "source": [
        "class SVM_Pa:\n",
        "    def __init__(self, gamma = -1, kernel = 'rbf', C = 1.0, eps = 1e-3):\n",
        "        self.C = C\n",
        "        self.eps = eps\n",
        "        self.gamma = gamma\n",
        "        self.tau = 1e-12\n",
        "        self.kernel = kernel\n",
        "        self.gamma = gamma\n",
        "    \n",
        "    def Kernel(self, x1, x2):\n",
        "        if self.kernel == 'rbf':\n",
        "            return self.rbf(x1, x2)\n",
        "        if self.kernel == 'linear':\n",
        "            return self.linear(x1, x2)\n",
        "   \n",
        "    def linear(self, x1, x2):\n",
        "        x1_temp = x1.astype(np.float64)\n",
        "        x2_temp = x2.astype(np.float64)\n",
        "        return x1_temp.dot(x2_temp)\n",
        "    \n",
        "    def rbf(self, x1, x2):\n",
        "        x1_temp = x1.astype(np.float64)\n",
        "        x2_temp = x2.astype(np.float64)\n",
        "        return np.exp(-self.gamma * (x1_temp.dot(x1_temp) + x2_temp.dot(x2_temp) - 2.0 * x1_temp.dot(x2_temp)))\n",
        "        \n",
        "    def select_B(self, X):\n",
        "        i = -1\n",
        "        G_max = -np.inf\n",
        "        G_min = np.inf\n",
        "        for t in range(self.l):\n",
        "            if (self.y[t] == 1 and self.alphas[t] <self.C) or \\\n",
        "            (self.y[t] == -1 and self.alphas[t] > 0):\n",
        "                if -self.y[t] * self.G[t] >= G_max:\n",
        "                    i = t\n",
        "                    G_max = -self.y[t] * self.G[t]\n",
        "        j = -1\n",
        "        obj_min = np.inf\n",
        "        for t in range(self.l):\n",
        "            if (self.y[t]==1 and self.alphas[t]>0) or \\\n",
        "                (self.y[t] == -1 and self.alphas[t] < self.C):\n",
        "                    b = G_max + self.y[t] * self.G[t]\n",
        "                    if -self.y[t]*self.G[t] <= G_min:\n",
        "                        G_min = -self.y[t] * self.G[t]\n",
        "                    if b>0:\n",
        "                        a = self.Q[i, i] + self.Q[t, t] - 2.0*self.y[i]*self.y[t]*self.Q[i, t]\n",
        "                        if a<=0:\n",
        "                            a = self.tau\n",
        "                        if -(b*b)/a <= obj_min:\n",
        "                            j = t\n",
        "                            obj_min = -(b*b)/a\n",
        "        if G_max - G_min < self.eps:\n",
        "            return -1, -1\n",
        "        return i, j\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.sign(self.dual_coef.dot(self.init_K(X)) - self.b)\n",
        "\n",
        "    @staticmethod\n",
        "    @cuda.jit \n",
        "    def init_K_kernel_rbf(X1, X2, K, n1, n2, m, gamma):\n",
        "        i, j = cuda.grid(2)\n",
        "        if i>= n1 or j >= n2:\n",
        "            return\n",
        "        sumii = np.float64(0)\n",
        "        sumij = np.float64(0)\n",
        "        sumjj = np.float64(0)\n",
        "        for k in range(m):\n",
        "            sumii += X1[i][k] * X1[i][k]\n",
        "            sumij += X1[i][k] * X2[j][k]\n",
        "            sumjj += X2[j][k] * X2[j][k]\n",
        "        K[i, j] = math.exp(-gamma * (sumii + sumjj - 2.0 * sumij))\n",
        "    \n",
        "    @staticmethod\n",
        "    @cuda.jit \n",
        "    def init_K_kernel_linear(X1, X2, K, n1, n2, m):\n",
        "        i, j = cuda.grid(2)\n",
        "        if i>= n1 or j >= n2:\n",
        "            return\n",
        "        sumij = np.float64(0)\n",
        "        for k in range(m):\n",
        "            sumij += X1[i][k] * X2[j][k]\n",
        "        K[i, j] = sumij\n",
        "        \n",
        "    def init_K(self, x):\n",
        "        d_x1 = self.X.astype(np.float64)\n",
        "        d_x2 = x.astype(np.float64)\n",
        "        d_K = cuda.device_array((self.l, x.shape[0]), np.float64)\n",
        "        blocksize = (32, 32)\n",
        "        gridsize = (math.ceil(self.l/blocksize[0]), math.ceil(x.shape[0]/blocksize[1]))\n",
        "        if self.kernel == 'rbf':\n",
        "            self.init_K_kernel_rbf[gridsize, blocksize](d_x1, d_x2, d_K, self.l, x.shape[0], self.n_features, self.gamma)\n",
        "        elif self.kernel == 'linear':\n",
        "            self.init_K_kernel_linear[gridsize, blocksize](d_x1, d_x2, d_K, self.l, x.shape[0], self.n_features)\n",
        "        return np.array(d_K.copy_to_host())\n",
        "\n",
        "    def get_b(self):\n",
        "        sum = 0.0\n",
        "        count = 0\n",
        "        for i in range(self.l):\n",
        "            if 0 < self.alphas[i] < self.C:\n",
        "                count += 1\n",
        "                sum += self.y[i] * self.G[i]\n",
        "        if count > 0:\n",
        "            self.b = sum/count\n",
        "            return\n",
        "        max = -np.inf\n",
        "        min = np.inf\n",
        "        for i in range(self.l):\n",
        "            if (self.alphas[i] == 0 and self.y[i] == -1) or \\\n",
        "                (self.alphas[i] == self.C and self.y[i] == 1):\n",
        "                    if max < self.y[i] * self.G[i]:\n",
        "                        max = self.y[i] * self.G[i]\n",
        "            if (self.alphas[i] == 0 and self.y[i] == 1) or \\\n",
        "                (self.alphas[i] == self.C and self.y[i] == -1):\n",
        "                    if min > self.y[i] *self.G[i]:\n",
        "                        min = self.y[i] * self.G[i]\n",
        "        self.b = (min+max) / 2\n",
        "    \n",
        "    @staticmethod\n",
        "    @cuda.jit \n",
        "    def init_Q_kernel_rbf(X, y, Q, n, m, gamma):\n",
        "        i, j = cuda.grid(2)\n",
        "        if i>= n or j >= n:\n",
        "            return\n",
        "        sumii = np.float64(0)\n",
        "        sumij = np.float64(0)\n",
        "        sumjj = np.float64(0)\n",
        "        for k in range(m):\n",
        "            sumii += X[i][k] * X[i][k]\n",
        "            sumij += X[i][k] * X[j][k]\n",
        "            sumjj += X[j][k] * X[j][k]\n",
        "        Q[i, j] = y[i]*y[j]*math.exp(-gamma * (sumii + sumjj - 2.0 * sumij))\n",
        "    \n",
        "    \n",
        "    @staticmethod\n",
        "    @cuda.jit \n",
        "    def init_Q_kernel_linear(X, y, Q, n, m):\n",
        "        i, j = cuda.grid(2)\n",
        "        if i>= n or j >= n:\n",
        "            return\n",
        "        sumij = np.float64(0)\n",
        "        for k in range(m):\n",
        "            sumij += X[i][k] * X[j][k]\n",
        "        Q[i, j] = y[i]*y[j]*sumij\n",
        "        \n",
        "    def init_Q(self):\n",
        "        d_x = self.X.astype(np.float64)\n",
        "        d_y = self.y.astype(np.float64)\n",
        "        d_Q = cuda.device_array((self.l, self.l), np.float64)\n",
        "        blocksize = (32, 32)\n",
        "        gridsize = (math.ceil(self.l/blocksize[0]), math.ceil(self.l/blocksize[1]))\n",
        "        if self.kernel == 'rbf':\n",
        "            self.init_Q_kernel_rbf[gridsize, blocksize](d_x, d_y, d_Q, self.l, self.n_features, self.gamma)\n",
        "        elif self.kernel == 'linear':\n",
        "            self.init_Q_kernel_linear[gridsize, blocksize](d_x, d_y, d_Q, self.l, self.n_features)\n",
        "        self.Q = np.array(d_Q.copy_to_host())\n",
        "    \n",
        "    @staticmethod\n",
        "    @cuda.jit\n",
        "    def compute_dual_coef_kernel(alpha, y, dual_coef, l):\n",
        "        i = cuda.grid(1)\n",
        "        if i > l:\n",
        "            return\n",
        "        dual_coef[i] = alpha[i] * y[i]\n",
        "\n",
        "    def compute_dual_coef(self):\n",
        "        blocksize = 32\n",
        "        gridsize = math.ceil(self.l/blocksize)\n",
        "        d_dualcoef = cuda.device_array(self.l, np.float64)\n",
        "        self.compute_dual_coef_kernel[gridsize, blocksize](self.alphas, self.y, d_dualcoef, self.l)\n",
        "        self.dual_coef = d_dualcoef.copy_to_host()\n",
        "        \n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.y = y\n",
        "        self.X = X\n",
        "        self.l, self.n_features = X.shape\n",
        "        if self.gamma == -1:\n",
        "            self.gamma = 1/(self.n_features*X.var())\n",
        "        self.alphas = np.zeros(self.l)\n",
        "        self.n_iter = 0\n",
        "        self.init_Q()\n",
        "        self.G = np.array([-1.0 for _ in range(self.l)])\n",
        "        while True:\n",
        "            i, j = self.select_B(X)\n",
        "            if j == -1:\n",
        "                break\n",
        "            self.n_iter += 1\n",
        "            alphai = self.alphas[i]\n",
        "            alphaj = self.alphas[j]\n",
        "            if y[i] != y[j]:\n",
        "                quad_coef = self.Q[i, i] + self.Q[j, j] + 2*self.Q[i, j]\n",
        "                if quad_coef <= 0:\n",
        "                    quad_coef = self.tau\n",
        "                delta = (-self.G[i] - self.G[j])/quad_coef\n",
        "                diff = alphai - alphaj\n",
        "                self.alphas[i] += delta\n",
        "                self.alphas[j] += delta\n",
        "                if diff > 0:\n",
        "                    if self.alphas[j]<0:\n",
        "                        self.alphas[j] = 0\n",
        "                        self.alphas[i] = diff\n",
        "                    if self.alphas[i]>self.C:\n",
        "                        self.alphas[i] = self.C\n",
        "                        self.alphas[j] = self.C - diff\n",
        "                else:\n",
        "                    if self.alphas[i]<0:\n",
        "                        self.alphas[i] = 0\n",
        "                        self.alphas[j] = -diff\n",
        "                    if self.alphas[j]>self.C:\n",
        "                        self.alphas[j] = self.C\n",
        "                        self.alphas[i] = self.C + diff\n",
        "            else:\n",
        "                quad_coef = self.Q[i, i] + self.Q[j,j] - 2*self.Q[i,j]\n",
        "                if quad_coef <=0:\n",
        "                    quad_coef = self.tau\n",
        "                delta = (self.G[i]-self.G[j])/quad_coef\n",
        "                sum = alphai + alphaj\n",
        "                self.alphas[i] -= delta\n",
        "                self.alphas[j] += delta\n",
        "                if sum>self.C:\n",
        "                    if self.alphas[i]>self.C:\n",
        "                        self.alphas[i] = self.C\n",
        "                        self.alphas[j] = sum-self.C\n",
        "                    if self.alphas[j]>self.C:\n",
        "                        self.alphas[j] = self.C\n",
        "                        self.alphas[i] = sum-self.C\n",
        "                else:\n",
        "                    if self.alphas[j]<0:\n",
        "                        self.alphas[j] = 0\n",
        "                        self.alphas[i] = sum\n",
        "                    if self.alphas[i]<0:\n",
        "                        self.alphas[i] = 0\n",
        "                        self.alphas[j] = sum\n",
        "            delta_ai = self.alphas[i] - alphai\n",
        "            delta_aj = self.alphas[j] - alphaj\n",
        "            self.G += self.Q[i, :] *delta_ai + self.Q[j, :]*delta_aj\n",
        "        self.compute_dual_coef()\n",
        "        self.get_b()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tài liệu tham khảo\n",
        "\n",
        "SVM bản cũ:\n",
        "https://www.pycodemates.com/2022/10/implementing-SVM-from-scratch-in-python.html\n",
        "\n",
        "SVM bản mới:\n",
        "http://cs229.stanford.edu/materials/smo.pdf\n",
        "\n",
        "https://www.microsoft.com/en-us/research/publication/sequential-minimal-optimization-a-fast-algorithm-for-training-support-vector-machines/\n",
        "\n",
        "https://www.csie.ntu.edu.tw/~cjlin/libsvm/\n",
        "\n",
        "https://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf\n",
        "\n",
        "https://www.csie.ntu.edu.tw/~cjlin/papers/quadworkset.pdf\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
